<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MixSynthFormer | Hexo</title>
  <meta name="keywords" content="">
  <meta name="description" content="MixSynthFormer | Hexo">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="description" content="presbyter的博客">
<meta property="og:type" content="website">
<meta property="og:title" content="categories">
<meta property="og:url" content="http://example.com/categories/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="presbyter的博客">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2022-03-22T11:42:07.000Z">
<meta property="article:modified_time" content="2022-03-22T11:42:07.809Z">
<meta property="article:author" content="presbyter">
<meta name="twitter:card" content="summary">


<link rel="icon" href="/img/avatar.jpg">

<link href="/css/style.css?v=1.1.0" rel="stylesheet">

<link href="/css/hl_theme/atom-light.css?v=1.1.0" rel="stylesheet">

<link href="//cdn.jsdelivr.net/npm/animate.css@4.1.0/animate.min.css" rel="stylesheet">

<script src="//cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>
<script src="/js/titleTip.js?v=1.1.0" ></script>

<script src="//cdn.jsdelivr.net/npm/highlightjs@9.16.2/highlight.pack.min.js"></script>
<script>
    hljs.initHighlightingOnLoad();
</script>

<script src="//cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script>



<script src="//cdn.jsdelivr.net/npm/jquery.cookie@1.4.1/jquery.cookie.min.js" ></script>

<script src="/js/iconfont.js?v=1.1.0" ></script>

<meta name="generator" content="Hexo 5.4.1"></head>
<div style="display: none">
  <input class="theme_disqus_on" value="false">
  <input class="theme_preload_comment" value="">
  <input class="theme_blog_path" value="">
  <input id="theme_shortcut" value="true" />
  <input id="theme_highlight_on" value="true" />
  <input id="theme_code_copy" value="true" />
</div>



<body>
<aside class="nav">
    <div class="nav-left">
        <a href="/"
   class="avatar_target">
    <img class="avatar"
         src="/img/avatar.jpg"/>
</a>
<div class="author">
    <span>presbyter</span>
</div>

<div class="icon">
    
        
            <a title="rss"
               href="/atom.xml"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-rss"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="github"
               href="https://github.com/yelog"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-github"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="facebook"
               href="https://www.facebook.com/faker.tops"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-facebook"></use>
                    </svg>
                
            </a>
        
    
        
    
        
    
        
            <a title="instagram"
               href="https://www.facebook.com/faker.tops"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-instagram"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="reddit"
               href="https://www.reddit.com/user/yelog/"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-reddit"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="weibo"
               href="http://weibo.com/u/2307534817"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-weibo"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="jianshu"
               href="https://www.jianshu.com/u/ff56736de7cf"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-jianshu"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="zhihu"
               href="https://www.zhihu.com/people/jaytp/activities"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-zhihu"></use>
                    </svg>
                
            </a>
        
    
        
    
        
            <a title="oschina"
               href="https://my.oschina.net/yelog"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-oschina"></use>
                    </svg>
                
            </a>
        
    
        
    
        
            <a title="email"
               href="mailto:jaytp@qq.com"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-email"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="qq"
               href="http://wpa.qq.com/msgrd?v=3&uin=872336115&site=qq&menu=yes"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-qq"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="kugou"
               href="https://www.kugou.com/"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-kugou"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="neteasemusic"
               href="https://music.163.com/#/user/home?id=88151013"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-neteasemusic"></use>
                    </svg>
                
            </a>
        
    
</div>





<ul>
    <li>
        <div class="all active" data-rel="全部文章">全部文章
            
                <small>(37)</small>
            
        </div>
    </li>
    
</ul>
<div class="left-bottom">
    <div class="menus">
        
            
            
            
    </div>
    <div>
        
            <a class="about  hasFriend  site_url"
               
               href="/about">关于</a>
        
        <a style="width: 50%"
                
                                           class="friends">友链</a>
        
    </div>
</div>
<input type="hidden" id="yelog_site_posts_number" value="37">

<div style="display: none">
    <span id="busuanzi_value_site_uv"></span>
    <span id="busuanzi_value_site_pv"></span>
</div>

    </div>
    <div class="nav-right">
        <div class="friends-area">
    <div class="friends-title">
        友情链接
        <i class="iconfont icon-left"></i>
    </div>
    <div class="friends-content">
        <ul>
            
            <li><a target="_blank" href="http://yelog.org/">叶落阁</a></li>
            
        </ul>
    </div>
</div>
        <div class="title-list">
    <div class="right-top">
        <div id="default-panel">
            <i class="iconfont icon-search" data-title="搜索 快捷键 i"></i>
            <div class="right-title">全部文章</div>
            <i class="iconfont icon-file-tree" data-title="切换到大纲视图 快捷键 w"></i>
        </div>
        <div id="search-panel">
            <i class="iconfont icon-left" data-title="返回"></i>
            <input id="local-search-input" autocomplete="off"/>
            <label class="border-line" for="input"></label>
            <i class="iconfont icon-case-sensitive" data-title="大小写敏感"></i>
            <i class="iconfont icon-tag" data-title="标签"></i>
        </div>
        <div id="outline-panel" style="display: none">
            <div class="right-title">大纲</div>
            <i class="iconfont icon-list" data-title="切换到文章列表"></i>
        </div>
    </div>

    <div class="tags-list">
    <input id="tag-search" />
    <div class="tag-wrapper">
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>2204.13656</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>轻量级多模态MRI分割</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>deep learning</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>lightweight multimodal MRI</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>multimodal MRI</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>Multimodal MRI</a>
            </li>
        
    </div>

</div>

    
    <nav id="title-list-nav">
        
        
        <a  class="全部文章 "
           href="/2024/10/15/PIDM/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="PIDM">PIDM</span>
            <span class="post-date" title="2024-10-15 15:49:21">2024/10/15</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2024/09/29/Animate-Anyone/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Animate Anyone">Animate Anyone</span>
            <span class="post-date" title="2024-09-29 10:24:14">2024/09/29</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2024/09/02/PATNet/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="PATNet">PATNet</span>
            <span class="post-date" title="2024-09-02 11:31:15">2024/09/02</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2024/06/27/Uplifting/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Uplifting">Uplifting</span>
            <span class="post-date" title="2024-06-27 20:26:01">2024/06/27</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2024/06/13/KTPFormer/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="KTPFormer">KTPFormer</span>
            <span class="post-date" title="2024-06-13 21:49:59">2024/06/13</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2024/05/29/GLA-GCN/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="GLA_GCN">GLA_GCN</span>
            <span class="post-date" title="2024-05-29 21:38:11">2024/05/29</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2024/05/23/PoseFormerV2/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="PoseFormerV2">PoseFormerV2</span>
            <span class="post-date" title="2024-05-23 20:20:16">2024/05/23</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2024/05/14/MixSynthFormer/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="MixSynthFormer">MixSynthFormer</span>
            <span class="post-date" title="2024-05-14 22:00:39">2024/05/14</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2024/05/11/Back-to-Optimization/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Back to Optimization">Back to Optimization</span>
            <span class="post-date" title="2024-05-11 16:02:43">2024/05/11</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2024/05/07/motionAGFormer/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="motionAGFormer">motionAGFormer</span>
            <span class="post-date" title="2024-05-07 21:29:07">2024/05/07</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2024/04/13/idea/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="idea">idea</span>
            <span class="post-date" title="2024-04-13 20:18:55">2024/04/13</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2024/03/22/RMT/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="RMT">RMT</span>
            <span class="post-date" title="2024-03-22 22:31:03">2024/03/22</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2024/03/16/MBANet/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="MBANet">MBANet</span>
            <span class="post-date" title="2024-03-16 17:05:16">2024/03/16</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2024/03/14/hybrid-filtering/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="hybrid filtering">hybrid filtering</span>
            <span class="post-date" title="2024-03-14 18:49:58">2024/03/14</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2024/03/04/Mamba-Unet/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Mamba_Unet">Mamba_Unet</span>
            <span class="post-date" title="2024-03-04 17:19:23">2024/03/04</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2024/01/21/swin-transformer/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="swin-transformer">swin-transformer</span>
            <span class="post-date" title="2024-01-21 10:27:29">2024/01/21</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2023/12/04/SegCoFusion/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="SegCoFusion">SegCoFusion</span>
            <span class="post-date" title="2023-12-04 23:32:33">2023/12/04</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2023/11/27/GMISeg-Note/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="GMISeg-Note">GMISeg-Note</span>
            <span class="post-date" title="2023-11-27 17:25:32">2023/11/27</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2023/11/18/IGN-Note/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="IGN Note">IGN Note</span>
            <span class="post-date" title="2023-11-18 22:11:46">2023/11/18</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2023/11/18/Fully-AutoMated-Multimodal-MRI-Based-Multi-Task-Learning/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="A Fully AutoMated Multimodal MRI-Based Multi-Task Learning">A Fully AutoMated Multimodal MRI-Based Multi-Task Learning</span>
            <span class="post-date" title="2023-11-18 16:45:53">2023/11/18</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2023/11/15/SFusion/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="SFusion">SFusion</span>
            <span class="post-date" title="2023-11-15 17:01:35">2023/11/15</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2023/11/11/%E5%9F%BA%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%88%90%E5%83%8F%E4%BD%93%E6%95%B0%E6%8D%AE%E8%9E%8D%E5%90%88/"
           data-tag="Multimodal MRI"
           data-author="" >
            <span class="post-title" title="基于卷积神经网络的成像体数据融合">基于卷积神经网络的成像体数据融合</span>
            <span class="post-date" title="2023-11-11 22:57:08">2023/11/11</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2023/11/05/CNL-UNet/"
           data-tag="lightweight multimodal MRI"
           data-author="" >
            <span class="post-title" title="CNL-UNet">CNL-UNet</span>
            <span class="post-date" title="2023-11-05 21:49:02">2023/11/05</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2023/11/04/SDS-Net/"
           data-tag="轻量级多模态MRI分割"
           data-author="" >
            <span class="post-title" title="SDS-Net">SDS-Net</span>
            <span class="post-date" title="2023-11-04 20:17:54">2023/11/04</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2023/10/29/MouseGan-Note/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="MouseGAN++ Note">MouseGAN++ Note</span>
            <span class="post-date" title="2023-10-29 21:30:43">2023/10/29</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2023/10/18/Voxelmorph/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Voxelmorph">Voxelmorph</span>
            <span class="post-date" title="2023-10-18 22:10:11">2023/10/18</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2023/10/09/summarize/"
           data-tag="multimodal MRI"
           data-author="" >
            <span class="post-title" title="summarize">summarize</span>
            <span class="post-date" title="2023-10-09 21:29:43">2023/10/09</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2023/09/25/PT-Net%E6%96%87%E7%8C%AE%E7%AC%94%E8%AE%B0/"
           data-tag="deep learning"
           data-author="" >
            <span class="post-title" title="PT-Net文献笔记">PT-Net文献笔记</span>
            <span class="post-date" title="2023-09-25 21:31:16">2023/09/25</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2023/09/20/56%E7%AC%94%E8%AE%B0/"
           data-tag="Multimodal MRI"
           data-author="" >
            <span class="post-title" title="56笔记">56笔记</span>
            <span class="post-date" title="2023-09-20 21:40:08">2023/09/20</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2023/09/13/Multi-modal-Machine-Learning-in-Engineering/"
           data-tag="2204.13656"
           data-author="" >
            <span class="post-title" title="Multi-modal MRI">Multi-modal MRI</span>
            <span class="post-date" title="2023-09-13 16:58:19">2023/09/13</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2023/09/12/%E5%A4%9A%E6%A8%A1%E6%80%81%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"
           data-tag="deep learning"
           data-author="" >
            <span class="post-title" title="多模态机器学习">多模态机器学习</span>
            <span class="post-date" title="2023-09-12 18:25:09">2023/09/12</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2023/09/10/deep-learning/"
           data-tag="deep learning"
           data-author="" >
            <span class="post-title" title="多模态三维医学图像配准算法研究">多模态三维医学图像配准算法研究</span>
            <span class="post-date" title="2023-09-10 00:03:32">2023/09/10</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2022/04/21/XSS/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="XSS">XSS</span>
            <span class="post-date" title="2022-04-21 22:17:16">2022/04/21</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2022/03/31/sqi/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="sqi">sqi</span>
            <span class="post-date" title="2022-03-31 19:15:02">2022/03/31</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2022/03/25/sqli/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="sqli">sqli</span>
            <span class="post-date" title="2022-03-25 22:33:12">2022/03/25</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2022/03/22/hello-world/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Hello World">Hello World</span>
            <span class="post-date" title="2022-03-22 19:08:06">2022/03/22</span>
        </a>
        
        
        <a  class="全部文章 "
           href="/2022/03/17/mysql-note/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="mysqlnote">mysqlnote</span>
            <span class="post-date" title="2022-03-17 23:31:16">2022/03/17</span>
        </a>
        
        <div id="no-item-tips">

        </div>
    </nav>
    <div id="outline-list">
    </div>
</div>

    </div>
    <div class="hide-list">
        <div class="semicircle" data-title="切换全屏 快捷键 s">
            <div class="brackets first"><</div>
            <div class="brackets">&gt;</div>
        </div>
    </div>
</aside>
<div id="post">
    <div class="pjax">
        <article id="post-MixSynthFormer" class="article article-type-post" itemscope itemprop="blogPost">
    
        <h1 class="article-title">MixSynthFormer</h1>
    
    <div class="article-meta">
        
        
        
        
    </div>
    <div class="article-meta">
        
            发布时间 : <time class="date" title='最后更新: 2024-05-20 21:47:59'>2024-05-14 22:00</time>
        
    </div>
    <div class="article-meta">
        
        
        <span id="busuanzi_container_page_pv">
            阅读 :<span id="busuanzi_value_page_pv">
                <span class="count-comment">
                    <span class="spinner">
                      <div class="cube1"></div>
                      <div class="cube2"></div>
                    </span>
                </span>
            </span>
        </span>
        
        
    </div>
    
    <div class="toc-ref">
    
        
    
<style>
    .left-col .switch-btn,
    .left-col .switch-area {
        display: none;
    }
    .toc-level-3 i,
    .toc-level-3 ol {
        display: none !important;
    }
</style>
</div>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>Human3.6m关键点编号</strong><br>‘hip’,  # 0<br>‘lhip’,  # 1<br>‘lknee’,  # 2<br>‘lankle’,  #<br>‘rhip’,  # 4<br>‘rknee’,  # 5<br>‘rankle’,  # 6<br>‘Spine (H36M)’,  # 7<br>‘neck’,  # 8<br>‘Head (H36M)’,  # 9<br>‘headtop’,  # 10<br>‘lshoulder’,  # 11<br>‘lelbow’,  # 12<br>‘lwrist’,  # 13<br>‘rshoulder’,  # 14<br>‘relbow’,  # 15<br>‘rwrist’,  # 16</p>
<p><strong>提出问题：</strong><br>问题1：视频中的人体姿态估计在各个领域都有广泛的实际应用，其中许多需要在资源稀缺的设备上进行快速推理，因此需要开发高效和准确的算法。<br>问题2：<br>以前的工作已经证明了利用运动连续性进行姿态估计使用稀疏采样帧与transformerbased模型的可行性。然而，这些方法只考虑了时间关系，而忽略了空间注意力，和点积自注意力计算的变压器的复杂性是二次成正比的嵌入大小。</p>
<p><strong>提出方法：</strong><br>为了解决这些限制，文章提出了MixSynthFormer，一个类似于Transformer的编码器模型，具有基于MLP的混合合成注意力。通过混合合成的空间和时间的注意力，模型结合了关节间和帧间的重要性，可以准确地估计在整个视频序列中的人体姿势从稀疏采样帧。</p>
<p>类似于运动完成，剩余帧中的姿态可以从关键帧姿态重构，这可以显著降低资源密集型姿态估计器的成本。</p>
<p>基于帧如何被馈送到模型中，姿势估计模型可以被分类为两种类型：逐帧估计器和基于关键帧的估计器。</p>
<p>常见的姿态估计框架估计每帧中的姿态，并通过知识蒸馏或模型结构设计来优化效率。然而，由于逐帧估计，计算成本仍然很高。此外，这些方法是敏感的遮挡情况下，部分关节是不可见的相机视图中，由于复杂的姿势或与环境的相互作用，导致不连贯的姿态，无论纳入时间信息。</p>
<p>相比之下，基于关键帧的姿态估计框架利用人体运动的连续性，可以产生更平滑的序列。只有关键帧用于重单帧估计，而其余帧中的姿势由轻量级模块恢复。</p>
<p><strong>文章要点</strong><br><img src="/2024/05/14/MixSynthFormer/Pipelines.png"><br><strong>图1</strong></p>
<p>基于关键帧的姿态估计框架流水线。恢复过程类似于插值。<br>(a)是基于特征的管道，它根据输入特征选择30%到40%的帧并恢复整个序列。</p>
<p>(b)是现有的基于采样的流水线，其使用采样器来选择帧并进行关键帧细化、全序列恢复和全序列细化。</p>
<p>(c)是本文提出的简化的基于采样的流水线，不包括关键帧细化。</p>
<p>文章提出了一个简化的recoverrefine流水线，如图1c所示。在本文的框架内，使用采样器选择关键帧，并使用采样器从关键帧中检测到的姿势中恢复姿势序列。然后使用单个细化模块对粗序列进行细化。</p>
<p>尽管有一系列的框架，但它们都没有将运动完成和预测视为两个相互依赖的任务。值得注意的是，运动完成和运动预测之间的唯一区别与关键帧约束有关。</p>
<p>文章提出了一种新的框架，利用轻量级的Transformer编码器的结构采样为基础的姿态估计。Transformer网络中的缩放点积自注意机制用于确定令牌相对于其他令牌的相对重要性。</p>
<p><strong>为了缓解使用大的嵌入大小时成本高的问题，文章用一个合成的自我关注模块来代替标准的关键字查询关注，该模块使用线性层来代替标准的关键字查询关注，该模块使用线性层来生成关注权重。为了提高改进的质量，文章综合了空间和时间的注意力矩阵，动态捕捉关节间和帧间的关系，来自两个维度的特征被组合并向前传递以供进一步处理。将模型命名为MixSynthFormer。</strong>（基于关键帧的姿态估计模型）</p>
<p>文章设计了一个基于MLP的混合合成注意力矩阵生成模块MixSynth Attention，它从输入表示中生成空间和时间上的注意力矩阵。这种设计使得模型能够动态地融合通道和令牌特征，并有效地优化姿势。为了加快计算速度，我们在注意力矩阵生成中引入了一个缩减因子，这进一步节省了计算而不影响性能。</p>
<p>根据关键帧的选择方式，基于关键帧的方法可以进一步分为两类：基于特征的和基于采样的。基于特征的方法选择依赖于中间特征表示的“好”关键帧，并在没有细化的情况下恢复整个序列。</p>
<p>基于采样的方法使用统一、随机或自定义的采样策略选择关键帧。由于所选择的帧可能不是“好的”，这些框架添加了细化模块来清除噪声姿态。</p>
<p><img src="/2024/05/14/MixSynthFormer/MixSynthFormer.png"><br><strong>图2</strong></p>
<p>MixSynthFormer从稀疏采样的关键帧中恢复和优化姿势。它由L个MixSynthEncoder块和两个线性投影层组成。MixSynthEncoder遵循标准的Transformer编码器结构，但用MixSynth Attention取代了多头自关注。MixSynth Attention通过SynthAttention操作合成空间和时间注意力（如图3所示）。两个分支的输出被合并并转发到线性层进行特征融合。（关键帧中检测到的姿势是彩色的，插值器恢复的姿势是灰色的。）</p>
<p>人体姿态估计本质上是一个关键点检测的项目，其目标是对身体的关键点进行检测。在这个过程中，可能会遇到关键点在连续帧之间的位置不连续或存在误差的情况。此时，插值技术可以被用来平滑这些关键点的位置，或者预测缺失的关键点位置。</p>
<p>具体来说，插值器可以根据已知的关键点位置，通过某种插值算法（如线性插值、多项式插值、样条插值等）来估计出未知或缺失的关键点位置。这可以帮助提高人体姿态估计的准确性和连续性。</p>
<p><strong>问题定义</strong>给定T帧的输入视频，采样器从每K帧（T是K的倍数）中采样一帧。采样帧被视为关键帧，其中将通过姿态估计来估计姿态。由于复杂的姿态或遮挡，从采样帧检测到的姿态可能是不可靠的。我们将从采样帧中检测到的姿态表示为Xsampled noisy ∈ R T K×P，它作为框架的输入。P是姿势参数的数量，其可以表示关节位置（2D&#x2F;3D）或旋转（6D），并且可以根据数据集和身体表示而变化。基于采样的位姿估计的目标是从采样帧中的检测位姿中恢复原始序列中的所有位姿态X ∈ RT × P（称为采样检测位姿）。</p>
<p><strong>模型概述</strong><br>MixSynthFormer的目标是恢复和优化姿态，以有效地获得准确的估计。最初，通过线性插值或线性层从采样的检测姿态恢复整个姿态序列。使用线性投影将这些恢复的姿势转换为姿势嵌入，并将其馈送到MixSynthEncoder的L个块中。每个MixSynthEncoder包括一个注意块和一个带有残差连接的前馈网络，后面是一个层归一化层。注意力块MixSynth Attention同时合成空间和时间注意力矩阵。通过整合空间和时间信息，我们的模型可以同时细化整个姿势序列。最后，通过另一个线性层输出恢复的姿态。</p>
<p><strong>MixSynthFormer结构设计</strong><br>文章采用了一个恢复细化管道。基于关键帧中检测到的姿态X，通过传统的或学习的姿态估计器沿时间维度沿着初步恢复整个姿态序列，记为x&#96;∈R T*P</p>
<p>从稀疏和有噪声的输入中恢复姿势会导致不准确的估计，这需要额外的处理来获得干净的输出。此外，传统的插值方法往往会产生过于平滑的运动序列，缺乏细节。</p>
<p>因此，细化步骤是必要的，以生成更精确的姿势序列，这可以被公式化为序列到序列的问题。Transformers在解决这些问题方面取得了显着的成功，因为它们能够捕捉令牌之间的全局相关性。除了用MixSynth Attention替换自注意模块之外，文章按照标准Transformer编码器的工作流程设计MixSynthFormer。</p>
<p>以下是MixSynthFormer的操作：</p>
<p>ˆX中的所有姿势都通过权重为W0∈Rp×C的线性层变换到姿势嵌入Z0∈RT×C，其中C是嵌入空间的维度。MixSynthEncoder的注意力层需要位置嵌入来指定输入标记的位置，而基于<strong>MLP</strong>的MixSynth注意在时间注意合成中对标记的顺序敏感，并且不需要额外的位置嵌入。</p>
<p><img src="/2024/05/14/MixSynthFormer/%E5%A7%BF%E6%80%81%E5%B5%8C%E5%85%A5.png"></p>
<p>{MLP指的是多层感知器（Multilayer Perceptron），它是一种人工神经网络（Artificial Neural Network, ANN）的类型。MLP是一种前向反馈神经网络，由多个神经元层组成，每个层与下一层全连接。</p>
<p>MLP至少包含三层：输入层、隐藏层（可以有多个）以及输出层。输入层负责接收原始数据，隐藏层负责对数据进行中间特征的提取，输出层负责输出最终的预测结果。在MLP中，每个神经元都与前一层的所有神经元相连，并具有权重和偏差。信息在网络中前向传播，通过乘以权重并加上偏差，然后通过激活函数进行非线性转换，从而在隐藏层和输出层之间传递。这种非线性转换使得MLP能够学习和表示复杂的非线性函数。}</p>
<p>姿势嵌入然后被传递到MixSynthEncode的L块中。由堆叠的MixSynth注意模块和前馈网络(FFN)组成，FFN是一个具有Gelu激活的两层逐点全连接层。在每个块之后依次应用剩余连接和层归一化(LN)。</p>
<p><img src="/2024/05/14/MixSynthFormer/MixSynthBlock.png"></p>
<p>这里，L∈[1，L]是指L的第一块。Zl−1是前一个编码块的输出，ˆZl是中间表示，Zl是当前编码块的输出。Zl和ˆZl在Rt×C中具有相同的维度。</p>
<p>在L个操作块之后，嵌入空间ZL中的特征通过另一个具有权重Wp ∈ RC × P的线性层被变换回姿势维度。残差连接的使用可以加快模型的收敛，并产生更稳定的结果。因此，最终恢复的姿态序列是来自MixSynthEncoder块的输出和初步恢复的噪声姿态的总和：</p>
<p><img src="/2024/05/14/MixSynthFormer/%E6%9C%80%E7%BB%88%E5%A7%BF%E6%80%81%E5%BA%8F%E5%88%97.png"></p>
<p><strong>MixSynth 注意力层</strong><br>为了学习全局和局部特征，它混合了空间和时间的合成注意力矩阵。这些矩阵中的权重反映了相对的关节间和帧间重要性。空间矩阵揭示了关节之间的相关性。当执行某些运动模式时，一起移动的关节高度相关。它有助于从相关关节中定位错误检测的关节，并进行准确检测。时间矩阵确定帧相对于序列中其他帧的影响，表示帧影响其余帧的程度。</p>
<p>合成注意力操作（SynthAttenOP）对Z ∈ RT×C进行操作，并输出特征Yi ∈ RT×C，其可以是空间的或时间的，分别表示为Ys和Yt。</p>
<p><img src="/2024/05/14/MixSynthFormer/%E5%90%88%E6%88%90%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%93%8D%E4%BD%9C.png"></p>
<p>同时生成空间和时间关注的特征。应用分裂注意力来重新平衡两个分支的贡献。不同的议案可以有不同的重点。关节间关系对于某些运动更重要，而其他运动可能更多地受到帧间关系的影响。Ys和Yt的权重Ay ∈ R2×C计算为：</p>
<p><img src="/2024/05/14/MixSynthFormer/%E6%9D%83%E9%87%8D%E8%AE%A1%E7%AE%97.png"></p>
<p>其中GAP表示全局平均池化函数，FFN包含两个具有ReLU激活的全连接层，Softmax用于归一化。加权和Yout ∈ RT×C是来自两个分支的级联表示与重新平衡权重Ay的逐元素乘积的总和：</p>
<p><img src="/2024/05/14/MixSynthFormer/%E6%9D%83%E9%87%8D%E8%BE%93%E5%87%BA.png"></p>
<p>MixSynth Attention块的输出通过用权重Wo ∈ RC×C线性变换Yout来获得：</p>
<p><img src="/2024/05/14/MixSynthFormer/MixSynth%E6%B3%A8%E6%84%8F%E5%8A%9B%E8%BE%93%E5%87%BA.png"></p>
<p><strong>SynthAttention</strong></p>
<p><img src="/2024/05/14/MixSynthFormer/SynthAttenOp.png"><br><strong>图3</strong></p>
<p>transformers中的自注意模块利用成对点积计算注意权重。查询密钥矩阵乘法的计算随着嵌入大小的增加而二次扩展。为了减轻嵌入大小对计算成本的影响，文章提出了合成注意力操作（SynthAttenOp），其计算量随着嵌入大小的增加而线性增长，作为标准注意力的替代品。SynthAttenOP使用线性层生成注意力矩阵。</p>
<p>SynthAttenOp在空间上和时间上运行。在空间注意合成中，输入和输出是互换的。这里我们用Z ∈ RN×D来说明一般情况，其中N和D可以用C或T代替。粗合成注意力矩阵As ∈ RN×N由具有权重Wz ∈ RD×N的线性层生成：</p>
<p><img src="/2024/05/14/MixSynthFormer/%E5%90%88%E6%88%90%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%9F%A9%E9%98%B5.png"></p>
<p>由于不同的框架或关节有不同的贡献，我们应用挤压和激发层（SELayer）来调节影响。它可以放大关键通道，同时减轻不太重要的影响。细粒度的注意力矩阵Asynth ∈ RN×N由以下公式获得：</p>
<p><img src="/2024/05/14/MixSynthFormer/%E7%BB%86%E7%B2%92%E5%BA%A6%E7%9F%A9%E9%98%B5.png"></p>
<p>其中GAP表示全局平均池化，GAP（A）∈ RN，δ和σ是Sigmoid激活和ReLU函数。减少比（rse）是一个经验发现的超参数，限制了模型的复杂性。Ws ∈ RN rse ×N是降维的，We ∈ RN× N rse是扩展到原始维数的.SELayer的输出是在与计算的权重逐通道相乘之后的重新缩放的输入。Softmax继承自标准的Transformer，它对注意力权重进行了归一化。与标准的Transformer编码器一致，输出是注意力矩阵和值的乘积：</p>
<p><img src="/2024/05/14/MixSynthFormer/%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%9F%A9%E9%98%B5%E5%92%8C%E5%80%BC%E7%9A%84%E4%B9%98%E7%A7%AF.png"></p>
<p>其中V &#x3D; Z ∈ RN × D且Y ∈ RN × D。上述方法适用于N相对较小的情况。当N较大时，由于等式n中的矩阵乘法，计算成本呈二次方增长。文章将缩减因子r应用于最后一个维度D，从而节省了等式中的计算。将降维表示为d &#x3D; N&#x2F;r。图3显示了简化注意力矩阵生成和特征融合的过程。通过下式获得约简的粗注意矩阵Ar s ∈ RN × d和约简值Vr ∈ Rd × D：</p>
<p><img src="/2024/05/14/MixSynthFormer/%E7%B2%97%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%9F%A9%E9%98%B5.png"></p>
<p>其中，用于减少注意力矩阵生成的权重和用于减少值的权重分别为Wrz ∈ RD×d和Wv ∈ Rd×N。</p>
<p>SELayer，即Squeeze-and-Excitation（SE）模块，是深度学习中的一种注意力机制模块，最初是在2017年由Hu等人提出的SENet（Squeeze-and-Excitation Networks）中引入的。SE模块的主要目标是通过显式地建模卷积特征通道之间的相互依赖关系来提高模型的表示能力。</p>
<p>SE模块主要由两部分组成：</p>
<p>Squeeze操作：这部分通过对每个通道的全局空间特征进行压缩（如通过全局平均池化）来得到一个通道描述符，该描述符能够捕获全局上下文信息。<br>Excitation操作：这部分使用一个简单的门控机制（如一个全连接层或两个全连接层组成的瓶颈结构），基于Squeeze操作得到的通道描述符来生成每个通道的调制权重。这些权重随后被用于重新校准（或缩放）原始特征图。<br>通过SE模块，模型能够学习到哪些通道是重要的并应该被强调，哪些通道是不重要的并应该被抑制。这种机制有助于提高模型的性能，特别是在处理具有复杂空间依赖关系的任务时。</p>
<p><strong>评估指标</strong><br>对于2D姿态估计，使用正确关键点百分比（PCK），并设置三个阈值（像素级下的边界框大小的20%、10%和5%）。对于3D任务，平均每关节位置误差（MPJPE）用于报告距离误差，平均加速度误差（Accel）用于反映估计的位姿序列的平滑性。</p>

      
       <hr><span style="font-style: italic;color: gray;"> 转载请注明来源，欢迎对文章中的引用来源进行考证，欢迎指出任何有错误或不够清晰的表达。可以在下面评论区评论，也可以邮件至 jaytp@qq.com </span>
    </div>
</article>


<p>
    <a  class="dashang" onclick="dashangToggle()">赏</a>
</p>






    




    </div>
    <div class="copyright">
        <p class="footer-entry">
    ©2016-2020 Yelog
</p>
<p class="footer-entry">Built with <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/yelog/hexo-theme-3-hexo" target="_blank">3-hexo</a> theme</p>

    </div>
    <div class="full-toc">
        <button class="full" data-title="切换全屏 快捷键 s"><span class="min "></span></button>
<a class="" id="rocket" ></a>

    </div>
</div>

<div class="hide_box" onclick="dashangToggle()"></div>
<div class="shang_box">
    <a class="shang_close"  onclick="dashangToggle()">×</a>
    <div class="shang_tit">
        <p>喜欢就点赞,疼爱就打赏</p>
    </div>
    <div class="shang_payimg">
        <div class="pay_img">
            <img src="/img/alipay.jpg" class="alipay" title="扫码支持">
            <img src="/img/weixin.jpg" class="weixin" title="扫码支持">
        </div>
    </div>
    <div class="shang_payselect">
        <span><label><input type="radio" name="pay" checked value="alipay">支付宝</label></span><span><label><input type="radio" name="pay" value="weixin">微信</label></span>
    </div>
</div>


</body>
<script src="/js/jquery.pjax.js?v=1.1.0" ></script>

<script src="/js/script.js?v=1.1.0" ></script>
<script>
    var img_resize = 'default';
    function initArticle() {
        /*渲染对应的表格样式*/
        
            $("#post .pjax table").addClass("green_title");
        

        /*渲染打赏样式*/
        
        $("input[name=pay]").on("click", function () {
            if($("input[name=pay]:checked").val()=="weixin"){
                $(".shang_box .shang_payimg .pay_img").addClass("weixin_img");
            } else {
                $(".shang_box .shang_payimg .pay_img").removeClass("weixin_img");
            }
        })
        

        /*高亮代码块行号*/
        

        /*访问数量*/
        
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js");
        

        /*代码高亮，行号对齐*/
        $('.pre-numbering').css('line-height',$('.has-numbering').css('line-height'));

        
        
    }

    /*打赏页面隐藏与展示*/
    
    function dashangToggle() {
        $(".shang_box").fadeToggle();
        $(".hide_box").fadeToggle();
    }
    

</script>

<!--加入行号的高亮代码块样式-->

<!--自定义样式设置-->
<style>
    
    
    .nav {
        width: 542px;
    }
    .nav.fullscreen {
        margin-left: -542px;
    }
    .nav-left {
        width: 120px;
    }
    
    
    @media screen and (max-width: 1468px) {
        .nav {
            width: 492px;
        }
        .nav.fullscreen {
            margin-left: -492px;
        }
        .nav-left {
            width: 100px;
        }
    }
    
    
    @media screen and (max-width: 1024px) {
        .nav {
            width: 492px;
            margin-left: -492px
        }
        .nav.fullscreen {
            margin-left: 0;
        }
    }
    
    @media screen and (max-width: 426px) {
        .nav {
            width: 100%;
        }
        .nav-left {
            width: 100%;
        }
    }
    
    
    .nav-right .title-list nav a .post-title, .nav-right .title-list #local-search-result a .post-title {
        color: #383636;
    }
    
    
    .nav-right .title-list nav a .post-date, .nav-right .title-list #local-search-result a .post-date {
        color: #5e5e5f;
    }
    
    
    .nav-right nav a.hover, #local-search-result a.hover{
        background-color: #e2e0e0;
    }
    
    

    /*列表样式*/
    

    /* 背景图样式 */
    
    


    /*引用块样式*/
    

    /*文章列表背景图*/
    

    
</style>







</html>
